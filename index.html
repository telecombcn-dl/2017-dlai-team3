<!DOCTYPE HTML>
<html>
	<head>
		<title>Audio2Faces</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<script src="js/jquery.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-layers.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-xlarge.css" />
		</noscript>
	</head>
	<body id="top">

		<!-- Header -->
			<header id="header" class="skel-layers-fixed">
				<h1><a href="#">TOP</a></h1>
				<nav id="nav">
 					<ul>
 						<li><a href="#authors">Authors</a></li>
 						<li><a href="#introduction">Introduction</a></li>
 	 					<li><a href="#dataset">Dataset generation</a></li>
 						<li><a href="#architecture">Architecture</a></li>
 						<li><a href="#problems_solutions">Problems and Solutions</a></li>
 						<li><a href="#vae">Variational Autoencoder</a></li>
 						<li><a href="#future_work">Future Work</a></li>
 					</ul>
 				</nav>
			</header>

		<!-- Banner -->
			<section id="banner">
				<div class="inner">
					<h2>DLAI Team 3 - Audio2Faces</h2>
				</div>
			</section>

		<!-- One -->
			<section id="authors" class="wrapper style1">
				<header class="major">
						<h2>Authors</h2>
				</header>

				<div class="container">
					<div class="row">
						<div class="3u">
							<section class="special box">
								<a href="https://www.linkedin.com/in/alejandro-woodward-a21a46100" class="image fit"><img src="images/AlejandroWoodward.jpg" alt="" /></a>
								<p>Alejandro Woodward</p>
							</section>
						</div>
						<div class="3u">
							<section class="special box">
								<a href="https://www.linkedin.com/in/irina-sánchez-muriana-65204311b/" class="image fit"><img src="images/irina.jpeg" alt="" /></a>
								<p>Irina Sanchez</p>
							</section>
						</div>
						<div class="3u">
							<section class="special box">
								<a href="https://www.linkedin.com/in/gen%C3%ADs-floriach-pigem-b74715b8/" class="image fit"><img src="images/genis.jpeg" alt="" /></a>
								<p>Genís Floriach</p>
							</section>
						</div>
						<div class="3u">
							<section class="special box">
								<a href="https://www.linkedin.com/in/oriol-vila-clarà-043867b9/" class="image fit"><img src="images/oriol.jpeg" alt="" /></a>
								<p>Oriol Vila</p>
							</section>
						</div>
					</div>
				</div>
			</section>
		<!-- Three -->
			<section id="introduction" class="wrapper style1">
				<header class="major">
					<h2>Introduction</h2>
				</header>
				<div class="container">
					<div class="row">
						<div class="6u">
							<section>
								<h2>Abstract</h2>
								<a class="image fit"><img src="images/2.png" alt="" /></a>
								<p> Our idea is to generate a talking face from an audio segment by using Generative Adversarial Networks (GANs). The architecture used is the proposed by David Berthelot, Thomas Schumm and Luke Metz in their work [Boundary Equilibrium Generative Adversarial Network (BEGAN)](https://arxiv.org/pdf/1703.10717.pdf).
								In our case, the input to the Generator network will be the audio features of an audio segment. Those features are obtained by passing the MFCC coefficients of the audio segment through a shallow CNN architecture. By doing that, we provide information to the generator network to be able to generate a face according to the provided audio segment.</p>
							</section>
						</div>
						<div class="6u">
							<section>
								<h3>Dataset</h3>
								<a class="image fit"><img src="images/3.png" alt="" /></a>
								<p>In order to train our network, we have also created our own dataset as we did not found any suitable one for our task. The goal was to generate a colection of Donal Trump face images with its asociated audio.
								To do so, first we extracted videos from the youtube platform. Then, we cropped them on the parts where Trump was speaking and we extracted the images and audio using a python script that we developed for such task.
								We wanted to have well centered faces and with the cleanest audio possible, for that reason we chosed to download videos from Donald Trump public speeches.
								Once the videos were selected, we had to process them to obtain both the face and the audio corresponding to the face. </p>
							</section>
						</div>
					</div>
				</div>
			</section>			

		<section id="dataset" class="wrapper style1">
				<div class="container">
					<div class="row">

						<div class="12u">
							<section>
								<h2>Dataset generation</h2>
								<a class="image fit"><img src="images/6.png" alt="" /></a>
								<p> In order to extract the face we resorted to the well known library for computer vision [OpenCV](https://opencv.org/). Using this library we extracted each frame of the video, then we processed each frame independently to extract the face. On the first iteration of our project we used the Viola Jones face detector. It worked pretty well but had some problems such as a high false positive rate and the fact that the faces where not centered inside the bounding box. To overcome this drawbacks and obtain a better dataset with less variance we changed the face detection algorithm.</p>
							</section>
						</div>
					</div>

				</div>
					
			</div>

		</section>

					</div>
				</div>
			</footer> 

	</body>
</html>