<!DOCTYPE HTML>
<html>
	<head>
		<title>ANPs</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<script src="js/jquery.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-layers.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-xlarge.css" />
		</noscript>
	</head>
	<body id="top">

		<!-- Header -->
			<header id="header" class="skel-layers-fixed">
				<h1><a href="#">TOP</a></h1>
				<nav id="nav">
 					<ul>
 						<li><a href="#authors">Authors</a></li>
 						<li><a href="#abstract">Abstract</a></li>
 	 					<li><a href="#architecture">Architecture</a></li>
 						<li><a href="#ANP_contributions">Title 2</a></li>
 						<li><a href="#results">Results</a></li>
 						<li><a href="https://github.com/imatge-upc/affective-2017-acmmm">Software</a></li>
 					</ul>
 				</nav>
			</header>

		<!-- Banner -->
			<section id="banner">
				<div class="inner">
					<h2>DLAI Team 3</h2>
				</div>
			</section>

		<!-- One -->
			<section id="authors" class="wrapper style1">
				<header class="major">
						<h2>Authors</h2>
				</header>

				<div class="container">
					<div class="row">
						<div class="3u">
							<section class="special box">
								<a href="https://www.linkedin.com/in/alejandro-woodward-a21a46100" class="image fit"><img src="images/AlejandroWoodward.jpg" alt="" /></a>
								<p>Alejandro Woodward</p>
							</section>
						</div>
					</div>
				</div>
			</section>
			
		<!-- Two -->
			<section id="two" class="wrapper style2">
				<header class="major">
					<h2>A joint collaboration between:</h2>
				</header>
				<div class="container">
					<div class="row">
						<div class="6u">
							<section class="special">
								<a href="https://imatge.upc.edu/web/" class="image fit"><img src="images/gpi.png" alt="" /></a>
								<h3>UPC Image Processing Group</h3>
							</section>
						</div>
						<div class="6u">
							<section class="special">
								<a href="http://www.columbia.edu/" class="image fit"><img src="images/Columbia-University.png" alt="" /></a>
								<h3>Columbia University</h3>
							</section>
						</div>
						<div class="6u">
							<section class="special">
								<a href="https://www.bsc.es" class="image fit"><img src="images/bsc.jpg" alt="" /></a>
								<h3>Barcelona Supercomputing Center</h3>
							</section>
						</div>
						<div class="6u">
							<section class="special">
								<a href="http://www.vilynx.com" class="image fit"><img src="images/vilynx.jpg" alt="" /></a>
								<h3>Vilynx</h3>
							</section>
						</div>
					</div>
				</div>
			</section>

		<!-- Three -->
			<section id="abstract" class="wrapper style1">
				<div class="container">
					<div class="row">
						<div class="8u">
							<section>
								<h2>Abstract</h2>
								<a class="image fit"><img src="images/abstract.png" alt="" /></a>
								<p> The increasing availability of affect-rich multimedia resources has bolstered interest in understanding sentiment and emotions in and from visual content. Adjective-noun pairs (ANP) are a popular mid-level semantic construct for capturing affect via visually detectable concepts such as “cute dog” or “beautiful landscape”. Current state-of-the-art methods approach ANP prediction by considering each of these compound concepts as individual tokens, ignoring the underlying relationships in ANPs.  This work aims at disentangling the contributions of the ‘adjectives’ and ‘nouns’ in the visual prediction of ANPs. Two specialised classifers, one trained for detecting adjectives and another for nouns, are fused to predict 553 different ANPs.  The resulting ANP prediction model is more interpretable as it allows us to study contributions of the adjective and noun components.</p>
							</section>
						</div>
						<div class="4u">
							<section>
								<h3>Affective Computing</h3>
								<p>Affective computing is the study and development of systems and devices that can recognize, interpret, process, and simulate human affect.</p>
							</section>
							<hr />
<!-- 							<section>
								<h3>Ante sed commodo</h3>
								<ul class="alt">
									<li><a href="#">Erat blandit risus vis adipiscing</a></li>
									<li><a href="#">Tempus ultricies faucibus amet</a></li>
									<li><a href="#">Arcu commodo non adipiscing quis</a></li>
									<li><a href="#">Accumsan vis lacinia semper</a></li>
								</ul>
							</section> -->
						</div>
					</div>
				</div>
			</section>			

		<section id="architecture" class="wrapper style1">
				<header class="major">
					<h2>Interpretable model for ANP detection</h2>
				</header>

				<div class="container">
					<div class="row">

						<div class="7u">
							<section>
								<h2>Fusion Model</h2>
								<a class="image fit"><img src="images/fusion_model.png" alt="" /></a>
								<p> This model that we propose is an interpretable architecture for ANP detection constructed by fusing the outputs of two specialized networks for adjective and noun classiffcation. We will refer to these two specialized networks as AdjNet and NounNet, correspondingly. The architecture for the specialized networks are based on the well-known ResNet-50 model. Residual Networks are convolutional neural network architectures that introduce residual functions with reference to the layer inputs, achieving better results than their non-residual counterparts.</p>
								<p>The last layer in ResNet-50, originally predicting the 1,000 classes in ImageNet, is replaced in AdjNet and NounNet to predict, respectively, the adjectives and nouns considered in our dataset.  Each of these two networks is trained separately with the same images and the corresponding adjective or noun labels.  The probability ouputs of AdjNet and NounNet are fused by means of a fully connected neural network with a ReLU non-linearity. On top of that, a softmax linear classiffer predicts the detection probabilities for each ANP class considered in the model.</p>
							</section>
						</div>

						<div class="5u">
							<section>
								<h2>Complete Fusion Model</h2>
								<a class="image fit"><img src="images/fusion_complete.png" alt="" /></a>
								<p>As shown in the image above, a whitening layer is added on top of the softmax classifier for both nouns and adjectives.  This layer consisted on simply subtracting the mean and dividing by the standard deviation.  </p>
								<p>In order to be able to calculate the Deep Taylor Decomposition across the fusion layer, there is no Batch Normalization in this layer even though it was used in the noun and adjective classifiers.</p>
							</section>
						</div>
					</div>

				</div>
					
			</div>

		</section>



		<section id="ANP_contributions" class="wrapper style1">
			<header class="major">
				<h2>ANP Contributions</h2>
			</header>

			<div class="container">
				<div class="row">

					<div class="row">
						<div class="5u">
							<section>
								<h3>Deep Taylor Decomposition</h3>
								<a href="http://www.heatmapping.org/deeptaylor/" class="image fit"><img src="images/dtd.png" alt="" /></a>
								
								<p>In order to compute how much the noun and the adjective contribute to the prediction of the ANP we use the method Deep Taylor Decomposition (DTD).  DTD is a method to explain individual neural network predictions in terms of input variables.  It operates by running a backward pass on the network using a predefined set of rules.  Deep Taylor decomposition is used to explain state-of-the-art neural networks for computer vision.</p>
								<ul class="actions">
									<li><a href="http://www.heatmapping.org/deeptaylor/" class="button alt">Learn More</a></li>
								</ul>
							</section>
						</div>
						<div class="7u">
							<section>
								<h3>Contributions calculation</h3>
								<a  class="image fit"><img src="images/model_dtd.png" alt="" /></a>
								<p>DTD will be applied through the ANP Softmax layer and Fusion layer in order to calculate the contribution of each of the nouns and adjective classes.  Once we know how much each noun and adjective have contributed for each ANP we can compute what is the proportion of contribution for nouns and adjectives.  We de ne the Adjective-to-Noun Ratio (ANR) as the normalized contribution of the adjectives with respect to the nouns during the prediction of an ANP.</p>
							</section>
						</div>
					</div>

				</div>
					
			</div>

		</section>



		<section id="results" class="wrapper style1">
			<header class="major">
				<h2>Results</h2>
			</header>

			<div class="container">
				<div class="row">

					<div id="results" class="row">
						<div class="12u">
							<section>
								<h3>Top contributions for nouns and adjectives</h3>
								<a class="image fit"><img src="images/top_contributions.png" alt="" /></a>
								
								<p> The most contributing adjectives and nouns detected by ANPnet can also be used as semantic labels themselves.  This way, our model can detect in a single pass additional concepts related to the predicted ANP, with applications to image tagging, captioning or retrieval.  On the two left columns we can see that there are ANPs (golden autumn/golden leaves and happy dog/smiling dog) with equivalent meanings which contributions are the same.  On the right columns, in example a) it can be seen how ANPnet learned that the most related concepts for an “elegant wedding” scene are the names“cake”, “rose”, “dress” and “lady”, and the adjectives “outdoor”, “fresh, “tasty” and “delicious”. </p>
							</section>
						</div>
						<div class="8u">
							<section>
								<h3>ANR examples</h3>
								<a  class="image fit"><img src="images/ANR.png" alt="" /></a>
								<p>In this table we can see the highest and lowest ANRs.  An ANR higher than 1 (upper part of the table) means that the contribution of the adjective is higher than the contribution of the noun.  In the lower part of the table we see tha ANPs with the lowest ANR.</p>
							</section>
						</div>

						<div class="4u">
							<section>
								<h3>Github code</h3>
								<a  href="" class="image fit"> <img src="images/github_logo.jpg" alt="" /></a>
								<p>Have a look at our code in our <a href="https://github.com/imatge-upc/affective-2017-acmmm">github repository.</a></p>
							</section>
						</div>
					</div>
				</div>
			</div>

		</section>
			
		<!-- Footer -->
<!-- 			<footer id="footer">
				<div class="container">
					<div class="row double">
						<div class="6u">
							<div class="row collapse-at-2">
								<div class="6u">
									<h3>Accumsan</h3>
									<ul class="alt">
										<li><a href="#">Nascetur nunc varius</a></li>
										<li><a href="#">Vis faucibus sed tempor</a></li>
										<li><a href="#">Massa amet lobortis vel</a></li>
										<li><a href="#">Nascetur nunc varius</a></li>
									</ul>
								</div>
								<div class="6u">
									<h3>Faucibus</h3>
									<ul class="alt">
										<li><a href="#">Nascetur nunc varius</a></li>
										<li><a href="#">Vis faucibus sed tempor</a></li>
										<li><a href="#">Massa amet lobortis vel</a></li>
										<li><a href="#">Nascetur nunc varius</a></li>
									</ul>
								</div>
							</div>
						</div>
						<div class="6u">
							<h2>Aliquam Interdum</h2>
							<p>Blandit nunc tempor lobortis nunc non. Mi accumsan. Justo aliquet massa adipiscing cubilia eu accumsan id. Arcu accumsan faucibus vis ultricies adipiscing ornare ut. Mi accumsan justo aliquet.</p>
							<ul class="icons">
								<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
								<li><a href="#" class="icon fa-pinterest"><span class="label">Pinterest</span></a></li>
							</ul>
						</div> -->
					</div>
				</div>
			</footer> 

	</body>
</html>